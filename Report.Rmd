---
title: "Predicting Newborn Weight"
author: Liam Coleman-Aulenbach, Venessa Keung, Lucy Wang
output: pdf_document
documentclass: article
---


```{r setup, include = FALSE}
# Knitr Configuration
knitr::opts_chunk$set(
  cache = TRUE,
  include = TRUE,
  echo = FALSE,
  results = "markup",
  fig.show = "asis",
  fig.height = 3.5,
  fig.align = "center"
)
```

```{r constants}
# Define all the functions and constants used later

# Category names for Ethnicity variates
ethLabels <- c(
  "Caucasian",
  "Mexican",
  "African-American",
  "Asian",
  "Mixed",
  "Other"
)

# Category names for Education variates
edLabels <- c(
  "Elementary School",
  "Middle School",
  "High School",
  "High School + Trade School",
  "High School + Some College",
  "College Graduate",
  "Trade School",
  "High School Unclear"
)

# Number of imputed datasets
k <- 5

# Unit conversion factors
poundsToKg <- 0.453592
inchesToM <- 0.0254

# The boundaries for BMI categories
# See this page for the source:
# https://www.mayoclinic.org/healthy-lifestyle/pregnancy-week-by-week/in-depth/pregnancy-weight-gain/art-20044360?pg=1
underweightNormalBoundary <- 18.5
normalOverweightBoundary <- 25
overweightObeseBoundary <- 30

# Use test 10% for test set in cross validation
testSetRatio = 0.1
```

```{r bmiFunctions}
isUnderweight <- function (bmi) bmi < underweightNormalBoundary
isNormal <- function (bmi) bmi < normalOverweightBoundary &
                           bmi >= underweightNormalBoundary
isOverweight <- function (bmi) bmi < overweightObeseBoundary &
                               bmi >= normalOverweightBoundary
isObese <- function (bmi) bmi >= overweightObeseBoundary

bmi <- function (wtLbs, htIn) (wtLbs * poundsToKg) / (htIn * inchesToM)^2
```

```{r numCigs}
# Roughly translate the "number" category to a floating point number of the actual number of cigarettes smoked
numCigs <- function (number) (number <= 4) * (5 * number - 2.5) +
                             (number > 4) * (10 * number - 25.5)
```

```{r decodeBirthVariates}
# Re-encoding and labelling variates as factors
decodeBirthVariates <- function (birthsDataset) {
  newDataset = data.frame(birthsDataset)

  newDataset$meth <- cut(
    birthsDataset$meth,
    breaks = c(0, 5:10), 
    labels = ethLabels,
    right = TRUE,
    include.lowest= TRUE
  )

  newDataset$med <- cut(
    birthsDataset$med,
    breaks = 0:8, 
    labels = edLabels,
    right = FALSE
  )

  newDataset$feth <- cut(
    birthsDataset$feth,
    breaks = c(0, 5:10),
    labels = ethLabels,
    right = TRUE,
    include.lowest= TRUE
  )

  newDataset$fed <- cut(
    birthsDataset$fed,
    breaks = 0:8, 
    labels = edLabels,
    right = FALSE
  )

  newDataset$smoke <- cut(
    birthsDataset$smoke,
    breaks = 0:4, 
    labels = c(
      "Never",
      "Smokes Now",
      "Until Pregnancy",
      "Doesn't Smoke Anymore"
    ),
    right = FALSE
  )

  newDataset$marital <- cut(
    birthsDataset$marital,
    breaks = 0:5,
    labels = c(
      "Married",
      "Legally Separated",
      "Divorced",
      "Widowed",
      "Never Married"
    )
  )

  newDataset$number <- numCigs(birthsDataset$number)

  newDataset$time <- cut(
    birthsDataset$time,
    breaks = 0:10,
    labels = c(
      "Never Smoked",
      "Still Smokes",
      "During Pregnancy",
      "Less Than A Year",
      "1-2 Years",
      "2-3 Years",
      "3-4 Years",
      "5-9 Years",
      "More Than 10 Years",
      "Quit But Don't Know When"
    ),
    right = FALSE
  )

  newDataset$income <- cut(
    birthsDataset$income,
    breaks = c(0, 1, 2, 10),
    labels = c(
      "Under 2500",
      "2500-4999",
      "5000-Over 25000"
    ),
    right = FALSE
  )

  newDataset
}
```

```{r smokingImpact}
smokingImpact <- function (time, number) {
  cigaretteEffectRatio = 6
  # Take the average of the bounds of the range of cigarettes smoked by a given category
  # as the approximate exact number of cigarettes smoked per day
  # https://www.med.uottawa.ca/sim/data/Smoking_and_Health_e.htm shows that it took a
  # six-fold increase in the number of cigarettes smoked a day to double the impact
  # on the likelihood of developing lung cancer. We approximate the effect of smoking
  # on birth with this ratio too.
  activeSmokingImpact = (number != 0) * 2^(numCigs(number) / cigaretteEffectRatio)
  
  impactTimeDecay = 2
  
  # Approximate a scalar number of years since quiting based on the categorical variable
  yearsQuit = (time >= 3) * (-2.5 + time) + (time >= 7) * (-18.5 + 3 * time)
  # Time = 1 or 2 are special cases with 0 decay
  yearsQuit = yearsQuit * (time >= 3)
  
  decayedSmokingImpact = activeSmokingImpact * exp(-yearsQuit / impactTimeDecay)
  
  decayedSmokingImpact
}
```

```{r engineeredFeatures}
craftFeatures <- function (imputedBirthsDataset) {
  newDataset = decodeBirthVariates(imputedBirthsDataset)

  newDataset$sameEth <- factor(
    imputedBirthsDataset$meth == imputedBirthsDataset$feth,
    labels = c("Different", "Same")
  )
  # What about "Other" though?
  
  newDataset$htDiff <- newDataset$fht - newDataset$mht
    
  newDataset$lateMom <- factor(
    newDataset$parity == 0 & newDataset$mage >= 35,
    labels = c("Not late", "Late")
  )

  newDataset$mBMI <- bmi(newDataset$mwt, newDataset$mht)
  
  newDataset$mBMICategory <- factor(
    1 * isNormal(newDataset$mBMI)
      + 2 * isOverweight(newDataset$mBMI)
      + 3 * isObese(newDataset$mBMI),
    labels = c("Underweight", "Normal", "Overweight", "Obese")
  )
  
  newDataset$smokingImpact <- smokingImpact(
    imputedBirthsDataset$time,
    imputedBirthsDataset$number
  )
  
  newDataset
}
```

```{r meanAIC}
meanAIC <- function (model, datasets) mean(sapply(
  datasets,
  function (dataset) AIC(update(model, data = dataset))
))
```

```{r selectModel}
selectModel <- function (
  datasets,
  predictedVar,
  excludedVars = c(),
  specialTerms = c()
) {
  selectedModelMeanAIC = .Machine$integer.max
  selectedModel = NULL
  
  for (dataset in datasets) {
    #adjustedBirthsDataset <- birthsDataset[, !colnames(birthsDataset) %in% excludedVars]
    M0 = lm(wt ~ 1, data = dataset)
    Mmax = lm(
      formula(paste(
        predictedVar,
        "~",
        "(.",
        Reduce(function (l, r) paste(l, r), Map(function (term) paste("-", term), excludedVars), ""),
        ")^2",
        Reduce(function (l, r) paste(l, r), Map(function (term) paste("+", term), specialTerms), "")
      )),
      data = dataset
    )
  
    candidateModel = step(
      lm(wt ~ 1, data = dataset),
      scope = list(lower = M0, upper = Mmax),
      direction = "both",
      trace = 0
    )
  
    candidateModelMeanAIC = mean(sapply(
      datasets,
      function (dataset) AIC(update(candidateModel, data = dataset))
    ))
  
    if (candidateModelMeanAIC < selectedModelMeanAIC) {
      selectedModel = update(candidateModel, data = dataset)
      selectedModelMeanAIC = candidateModelMeanAIC
    }
  }
  
  selectedModel
}
```

```{r crossValidate}
crossValidate <- function (model1, model2, datasets) {
  # "Usually about a thousand is fine" - M. Lysy, Nov. 27, 2018
  m = 1000

  model1rPMSE <- vector(mode = "numeric", length = m)
  model2rPMSE <- vector(mode = "numeric", length = m)

  for (i in 1:m) {
    chosenSet = datasets[[1 + i %% k]]
    Ntotal = nrow(chosenSet)
    Ntest = floor(Ntotal * testSetRatio)
    outOfSampleIndices = sample(Ntotal, Ntest)
    trainSet = chosenSet[-outOfSampleIndices, ]
    testSet = chosenSet[outOfSampleIndices, ]
    
    model1 = update(model1, data = trainSet)
    model2 = update(model2, data = trainSet)
    outOfSamplePredictions1 = predict(model1, newdata = testSet)
    outOfSamplePredictions2 = predict(model2, newdata = testSet)
    predictionErrors1 = (testSet$wt - outOfSamplePredictions1) ^ 2
    predictionErrors2 = (testSet$wt - outOfSamplePredictions2) ^ 2
    model1rPMSE[i] <- sqrt(sum(predictionErrors1) / Ntest)
    model2rPMSE[i] <- sqrt(sum(predictionErrors2) / Ntest)
  }
  
  list(
    rPMSEs = data.frame(model1 = model1rPMSE, model2 = model2rPMSE),
    residuals = data.frame(
      actual = testSet$wt,
      model1Predictions = outOfSamplePredictions1,
      model2Predictions = outOfSamplePredictions2,
      model1 = outOfSamplePredictions1 - testSet$wt,
      model2 = outOfSamplePredictions2 - testSet$wt
    )
  )
}
```

```{r import}
# Import
births <- read.csv("chds_births.csv")
```

```{r mend}
mendedBirths <- data.frame(births)
mendedBirths[mendedBirths$marital == 0, "marital"] <- NA
```

```{r mice}
library(mice)
options(warn=-1)

multiplyImputedBirths <- mice(
  mendedBirths,
  m = k,
  method = "pmm",
  seed = 500,
  printFlag = FALSE
)

imputedBirths <- lapply(1:k, function(i) complete(multiplyImputedBirths, i))
```

```{r decodeBirths}
decodedImputedBirths <- lapply(imputedBirths, decodeBirthVariates)
```

```{r craftFeatures}
engineeredFeatureBirths <- lapply(imputedBirths, craftFeatures)
```


# Summary

The purpose of this study was to determine what factors affect a male baby's birth weight with information readily available when the couple conceives. A sample of 1236 newborn males was conducted and information was taken via a survey of the mothers. The factors considered in this study were mother's age, mother's weight, father's ethnicity, the amount of time since the mother had stopped smoking, and parity. Furthermore, we engineered variables showing the mothers' pregnancy BMI, a smoking index to reflect the affects of smoking on the mothers' bodies, whether or not the parents were of the same ethnicity, and the height difference between the father and the mother. These variables were created either because the given variates were not an accurate predictor of health, or because we thought they would also be predictors of a baby's weight. Results of the study show that ______.


# Model Selection

## Data Diagnostic

### Data Exploration

Looking at the data beforehand, we tried to test if any of the variables that would be assumed to have a relationship with baby weight had a relationship in the context of the data. 

```{r 1}
pairs(
  births[c("wt", "mht", "mwt","time", "number")],
  col = adjustcolor("firebrick", 0.2),
  pch = 19,
  main = "Pairs Plot"
)
```

We found that the babies' weight had a positive relationship with the mothers' weight as well as with the mothers' height. We also see that the mothers' height has a positive relationship with the mothers' height.

We also tried to find the distribution of the babies' weight. In doing so, we tested to see if the babies' weight followed a Normal distribution. If it did not, we would have had to apply an affine transformation to the data to make it follow a Normal distribution.

```{r 2}
hist(
  births$wt,
  breaks = 100,
  col = "firebrick",
  main = "Frequency of Birth Weights",
  xlab = "Birth Weight (ounces)",
  mar = c(1, 4, 1, 2) +0.1
) 
```

Looking at the data, we see that the distribution of the babies' weight is close to Normal, but has spikes in frequency in certain areas.

We then decided to test the relationship between the mothers' ethnicity and the babies' weight. According to a 2009 study published in the British Journal of Nutrition, BMI was found to be an inaccurate measurement for non-white individuals. BMI, as a measure of weight proportional to the area of an individual's body, was found to differ among races. Hence, it seems to be a viable factor when considering the weight of a newborn baby.

```{r 3}
plot(
  births$meth,
  births$wt,
  col = adjustcolor("firebrick", 0.5),
  pch = 16,
  main = "Mother's Ethnicity vs Birth Weight",
  xlab = "Mother's Ethnicity",
  ylab = "Birth Weight (ounces)",
  mar = c(1, 4, 1, 2) +0.1
)
```

However, based on the data, there was no evidence of a linear relationship between only the mothers' ethnicity and the babies' weight.

Next, we tested for a relationship between parity and the babies' weight. As a mother's body adjusts to pregnancy, it would make sense for the babies' weight to be affected.

```{r 4}
plot(
  births$parity,
  births$wt,
  pch = 16,
  col = "firebrick",
  main = "Parity vs Birth Weight",
  xlab = "Parity",
  ylab = "Birth Weight (ounces)"
)
```

Based on the data, we see no evidence of a linear relationship between only babies' weight and parity.

Finally, we tested for a relationship between the mothers' education level, fathers' education level, mothers' age at the termination of the pregnancy, and household income with the babies' weight. A household with a higher income would be able to provide more resources to a pregnant mother and would have a higher likelihood of having a healthy mother, who would likely give birth a baby with a healthy baby weight. A household with a higher income would likely have a highly educated mother, or highly educated father, or both.

We also tested for a relationship between mothers' education level and fathers' education level. A mother with a lower education level, which would make sense given that the data is taken from 1960-1967, may be more inclined to marry a man with a higher education level in order to provide for herself and a future child.

```{r 5}
par(mfrow = c(2,2))
plot(
  births$med,
  births$wt,
  col = adjustcolor("firebrick", 0.5),
  pch = 16,
  main = "Mother's Education vs Birth Weight",
  xlab = "Mother's Education",
  ylab = "Birth Weight (ounces)"
)
plot(
  births$fed,
  births$wt,
  col = adjustcolor("firebrick", 0.5),
  pch = 16,
  main = "Father's Education vs Birth Weight",
  xlab = "Father's Education",
  ylab = "Birth Weight (ounces)"
)
plot(
  births$mage,
  births$wt,
  pch = 16,
  col = "firebrick",
  main = "Mother's Age vs Birth Weight",
  xlab = " Mother's Age",
  ylab = "Birth Weight (ounces)"
) 
plot(
  births$income,
  births$wt,
  pch = 16,
  col = "firebrick",
  main = "Household Income vs Birth Weight",
  xlab = "Household Income (USD)",
  ylab = "Birth Weight (ounces)"
)
```

However, we see that none of the tested variables: mothers' education level, fathers' education level, mothers' age  at the termination of pregnancy, or household income have a linear relationship with the babies' weight.


We also tried to test if any of the engineered variables: difference between father and mother height, and BMI, had a relationship with weight.

According to a 2011 study, it was found that a difference between parental height contributed to whether or not the mother would require an Emergency Cesarean Section (ECS). Since ECS can be used when a baby is too big for the birth canal or to save the baby in before it comes to term, there is a possibility that it is related to birth weight.

Looking at the heights of the mothers and the fathers, we see that majority of the couples had fathers who were taller than the mothers. It is also worth nothing that the mean baby weight when the father is taller than the mother is greater than the mean baby weight when the mother is taller than the father. This suggests a possible relationship between the difference in heights.

```{r 6}
par(mfrow = c(1,2))
plot(
  births$mht,
  births$fht,
  col = adjustcolor("firebrick", 0.25),
  pch = 16,
  main = "Mother vs Father Height",
  xlab = "Mother's Height (inches)",
  ylab = "Father's Height (inches)"
)
abline(coef = c(0, 1))
plot(
  births$fht - births$mht,
  births$wt,
  pch = 16,
  col = "firebrick",
  main = "Difference in Height vs Weight",
  xlab = "Difference in Height (inches)",
  ylab = "Birth Weight (ounces)"
)
```

Based on the data, there does not appear to be a relationship between only the difference in parental height and the babies' weight.

BMI, as a relatively good indicator of health, would theoretically be a good indicator of health of a newborn baby. We want to look at the mothers' BMI to see whether that would have a relationship with the baby's newborn weight.

```{r BMI}
plot(
  bmi(births$mwt, births$mht),
  births$wt,
  pch = 16,
  col = "firebrick",
  main = "Mother's BMI vs Birth Weight",
  xlab = "Mother's BMI (kg/m^2)",
  ylab = "Birth Weight (ounces)"
)
```

Based on the data, there appears to be a small positive relationship between the mothers' BMI and the babies' weight.


We did not consider gestation as a factor of birth weight because it was not something that the couple could know at conception of the baby. 

```{r gestation}
plot(
  births$gestation,
  births$wt,
  main = "Gestation Period vs Birth Weight",
  xlab = "Gestation Period (days)",
  ylab = "Birth Weight (ounces)"
)
```

We also found that gestation was very closely related to births, indicating that predicting gestation period is conceptually similar to predicting birth weight.

### Outliers
We discovered some values outside of the defined encodings. For example, in the marital column there were two 0s, which have no corresponding marital status. We overwrote those (likely) transcription errors with NAs which were later filled in with multiple imputation.

```{r outliers}
paste("Number of Occurrences per Marital Status category")
summary(factor(births$marital))
```

### Missing Data

```{r NAs}
N <- nrow(mendedBirths)

round(sapply(colnames(mendedBirths), function (colname) sum(is.na(mendedBirths[colname])) / N), 2)
nrow(na.omit(mendedBirths[, !(colnames(mendedBirths) %in% c("fht", "fwt", "income"))])) / N
```

## Data Preprocessing

### Filling Missing Values

When looking at the data, around 40% of the entries both in father's weight and father's height were NA. The data was included and values using MICE were substituted. Income also had about 10% of entries with NA. These values, as well as any other category with NA, were substituted with MICE. The three aforementioned factors affected the baby's weight very minimally, but were included to preserve the integrity of the data. Without father height, father weight, and income, the percentage of the original data considered would be reduced to 90.3%.

### Decoding

## Candidate Model 1

Model 1 is constructed using raw data with decoded categorical datasets. The automated selection process uses stepwise selection.

```{r model1}
basicBirthWeightModel <- selectModel(
  decodedImputedBirths,
  "wt",
  excludedVars = c("gestation", "smoke")
)
basicBirthWeightModelMeanAIC <- meanAIC(basicBirthWeightModel, decodedImputedBirths)
```

## Candidate Model 2

Model 2 uses an engineered data, which includes the difference between mother and father's heights(htDiff), mother's (mBMI), mother's BMI category(mBMICategory), and smoking impact(smokingImpact).

The mother's BMI category is defined as the following:

\begin{center}
\begin{tabular}{|c|c|}
\hline
BMI Category & Range ($kg/m^2$) \\
\hline
Underweight & <18.5 \\
Normal & [18.5, 25) \\
Overweight & [25, 30] \\
Obese & > 30 \\
\hline
\end{tabular}
\end{center}

The smoking impact is calculated as follows if $number {\neq} 0$:
$$
Smoking\ Impact = \begin{cases}
 ({2^{\gamma / \alpha}}) * {e^{-{\lambda}/{\beta}}} &\textrm{ if } \gamma > 0\\
 0 &\textrm{ if } \gamma = 0
\end{cases}
$$
where ${\alpha}$ = cigaretteEffectRatio = 6 , ${\gamma}$ = numCigs, ${\lambda}$ = yearsQuit, and ${\beta}$ = impactTimeDecay = 2


### Automated Model Selection
```{r model2}
engineeredBirthWeightModel <- selectModel(
  engineeredFeatureBirths,
  "wt",
  c("gestation", "smoke", "time", "fht", "mBMICategory"),
  c("time")#, smokingImpact:smokingQuitCategory")
  #c("smokingImpact", "mBMI", "htDiff", "sameEth",  "lateMom")
)
engineeredBirthWeightModelMeanAIC <- meanAIC(
  engineeredBirthWeightModel,
  engineeredFeatureBirths
)
```


# Model Diagnostics

## Significance

```{r leverage}

# Cook's Distance vs. Leverage for Basic Model
D <- cooks.distance(basicBirthWeightModel) 
infl.ind <- which.max(D)
h <- hatvalues(basicBirthWeightModel)
p <- length(coef(basicBirthWeightModel))
n <- nobs(basicBirthWeightModel)
hbar <- p/n
lev.ind <- h > 2*hbar 
clrs <- rep("black", len = n)
clrs[lev.ind] <- "blue"
clrs[infl.ind] <- "red"
par(mfrow = c(1,1), mar = c(4,4,1,1))
cex <- .8

# Cook's Distance vs. Leverage for Engineered Model
D2 <- cooks.distance(engineeredBirthWeightModel) 
infl.ind2 <- which.max(D2) 
h2 <- hatvalues(engineeredBirthWeightModel)
p2 <- length(coef(engineeredBirthWeightModel))
n2 <- nobs(engineeredBirthWeightModel)
hbar2 <- p2/n2
lev.ind2 <- h2 > 2*hbar2 
clrs2 <- rep("black", len = n)

clrs2[lev.ind2] <- "blue"
clrs2[infl.ind2] <- "red"
par(mfrow = c(1,1), mar = c(4,4,1,1))
cex <- .8

par(mfrow = c(1,2))
plot(h, D, xlab = "Leverage", ylab = "Cook's Influence Measure", main = "Leverage for Basic Model", pch = 21, bg = clrs, cex.main = 0.9, cex.axis = cex)
abline(v = 2*hbar, col = "grey60", lty = 2) # 2x average leverage
legend("topleft", legend = c("High Leverage", "High Influence"), pch = 21,pt.bg = c("blue", "red"), cex = cex, pt.cex = cex)

plot(h2, D2, xlab = "Leverage", ylab = "Cook's Influence Measure", main = "Leverage for Engineered Model", pch = 21, bg = clrs, cex.main = 0.9, cex.axis = cex)
abline(v = 2*hbar2, col = "grey60", lty = 2) # 2x average leverage
legend("topleft", legend = c("High Leverage", "High Influence"), pch = 21,pt.bg = c("blue", "red"), cex = 0.5, pt.cex = cex)
```

Looking at the plot of the Cook's distance vs Leverage, both models have one extremely high influential data point and about the same amount of high influential data points. This can indicate that the amount of outliers in the two datasets are around the same.

## PRESS Stastic and AIC
```{r PRESS and AIC}
press1 <- resid(basicBirthWeightModel)/(1-hatvalues(basicBirthWeightModel)) 
press2 <-  resid(engineeredBirthWeightModel)/(1-hatvalues(engineeredBirthWeightModel))
AIC1 <- c("Basic", "Engineered")

#display results
disp <- rbind(AIC = c(engineeredBirthWeightModelMeanAIC, basicBirthWeightModelMeanAIC),PRESS = c(sum(press1^2), sum(press2^2)))
colnames(disp) <- c("Basic", "Engineered")
disp
```

Looking at the PRESS statistic and the AIC of both models, AIC is favouring the Basic Model, while the PRESS statistic favours the Engineered data. However the PRESS statistic has a larger relative difference in the two models compared to AIC, so overall the Engineered Model is preferred using these statistical analysis


## Cross-Validation
```{r crossValidation}
cvResults <- crossValidate(
  basicBirthWeightModel,
  engineeredBirthWeightModel,
  engineeredFeatureBirths
)
```

Based on the rPMSEs, we see that the mean for the Engineered Model is greater than that of the Basic Model, and the standard deviation of the Engineered Model is less than that of the Basic Model.

```{r crossVData}
rPMSEs <- cvResults$rPMSEs
paste(mean(rPMSEs$model1), sd(rPMSEs$model1))
paste(mean(rPMSEs$model2), sd(rPMSEs$model2))
boxplot(list(model1rPMSE = rPMSEs$model1, model2rPMSE = rPMSEs$model2))

par(mfrow=c(1,2))
plot(cvResults$residuals$model1Predictions, cvResults$residuals$model1,  main = "Predicted Values vs Basic Model Res", xlab = "Predicted Values", ylab = "Basic Model Residuals", cex.main= 0.8)
plot(cvResults$residuals$model2Predictions, cvResults$residuals$model2, main = "Predicted Values vs Engineered Model Res", xlab = "Predicted Values", ylab = "Engineered Model Residuals", cex.main=0.8)
```

Then, by plotting the QQ-Plots of residuals of the predicted values vs actual residuals, we found that both models showed evidence of Normality, but for lighter babies, erred on the side of over-predicting their weight, and for heavier babies, erred on the side of under-predicting their weight. See Appendix Figure 1.9.


We then looked at the residual plots. Plotting residuals against fitted values, we saw evidence of the data not showing any non linear relationships in both models.

By plotting the Normal Q-Q Plot, we found strong evidence of Normality of the errors in both models.
```{r qq2}

par(mfrow = c(1,2))
qqnorm(cvResults$residuals$model1, main = "Normal Q-Q Plot for Basic", cex.main = 0.85)
abline(a = 0, b = 20, lty = 2, col = "blue")

qqnorm(cvResults$residuals$model2, main = "Normal Q-Q Plot for Engineered", cex.main = 0.85)
abline(a = 0, b = 20, lty = 2, col = "blue")
```

# Discussion

We see that the model violates the constant variance model, as seen with the standard deviation of parity (See Appendix Figure 1.8)

\pagebreak

# Appendix

```{r setupAppendix, include = FALSE, cache = FALSE}
# Reconfigure Knitr for Appendix
knitr::opts_chunk$set(include = TRUE, echo = TRUE, eval = FALSE)
```

## Section 1: Constants and Functions

### Chunk 1
```{r ref.label = "constants"}
```

### Chunk 2
```{r ref.label = "bmiFunctions"}
```

### Chunk 3
```{r ref.label = "numCigs"}
```

### Chunk 4
```{r ref.label = "decodeBirthVariates"}
```

### Chunk 5
```{r ref.label = "smokingImpact"}
```

### Chunk 6
```{r ref.label = "engineeredFeatures"}
```

### Chunk 7
```{r ref.label = "meanAIC"}
```

### Chunk 8
```{r ref.label = "crossValidate"}
```

## Section 2: Dataset Definitions

### Chunk 1
```{r ref.label = "import"}
```

### Chunk 2
```{r ref.label = "mend"}
```

### Chunk 3
```{r ref.label = "mice"}
```

### Chunk 4
```{r ref.label = "decodeBirths"}
```

### Chunk 5
```{r ref.label = "craftFeatures"}
```

## Section 3: Figures

### Figure 1.1

Produces a pair plot of the variables birth weight, mother height, mother weight, time (since quitting smoking), and number (number of cigarettes smoke per day while smoking)
```{r ref.label = "1"}
```

### Figure 1.2

Plot
```{r ref.label = "2"}
```

### Figure 1.3

Plot
```{r ref.label = "3"}
```

### Figure 1.4

Plot
```{r ref.label = "4"}
```

### Figure 1.5

Plot
```{r ref.label = "5"}
```

### Figure 1.6

Plots the birth weight against the difference in height of the parents
```{r ref.label = "6"}
```

### Figure 1.7

Plots the birth weight against the BMI of the mother
```{r ref.label = "BMI"}
```


### Figure 2.1

Plot
```{r ref.label = "resid"}
```

### Figure 2.2

Plot
```{r ref.label = "qq"}
```

### Figure 2.3

Plot
```{r ref.label = "qq2"}
```


### Figure 3.1

Plot
```{r violateEqualVar, eval = TRUE}
round(
  sapply(
    0:13,
    function (parity) c(
      mean(births[births$parity == parity, "wt"]),
      sd(births[births$parity == parity, "wt"])
    )
  ),
  2
)
```

### Figure 3.2

Plot
```{r extraQQ, eval = TRUE}
qqplot(
  cvResults$residuals$model1Predictions,
  cvResults$residuals$actual,
  main = "Q-Q Plot",
  xlab = "Predicted Values",
  ylab = "Actual Values"
)
abline(a = 0, b = 1, lty = 2, col = "red")

qqplot(
  cvResults$residuals$model2Predictions,
  cvResults$residuals$actual,
  main = "Q-Q Plot",
  xlab = "Predicted Values",
  ylab = "Actual Values"
)
abline(a = 0, b = 1, lty = 2, col = "red")
```


```{r ref.label = "gestation"}
```


```{r ref.label = "outliers"}
```


```{r ref.label = "NAs"}
```



```{r ref.label = "model1"}
```



```{r ref.label = "model2"}
```


```{r ref.label = "leverage"}
```


```{r ref.label = "crossValidation"}
```
